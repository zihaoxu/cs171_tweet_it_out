{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tweet import config\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractHashTags(tweets, preprocess=False):\n",
    "    '''Extract # information from tweets'''\n",
    "    pattern = \"\\#\\w+\"\n",
    "    hashtag = []\n",
    "    for t in tweets:\n",
    "        if preprocess:\n",
    "            raw_tags = re.findall(pattern, t)\n",
    "            tags = []\n",
    "            for t in raw_tags:\n",
    "                if 'covid' in t.lower() or 'virus' in t.lower():\n",
    "                    t = t[1:].lower().replace(\"_\", \"\").replace(\"ãƒ¼\", \"\")\n",
    "                    # Collapse covid and covid19\n",
    "                    if t == \"covid\": t = \"covid19\" \n",
    "                    if 'corona' in t: t = 'coronavirus'\n",
    "                    tags.append(\"#\" + t.title())\n",
    "                else:\n",
    "                    tags.append(t)\n",
    "        else:\n",
    "            tags = re.findall(pattern, t)\n",
    "        hashtag.append(tags)\n",
    "    return hashtag\n",
    "\n",
    "def save_json(node_json, edge_json, node_path, edge_path):\n",
    "    with open(node_path, 'w') as outfile:\n",
    "        json.dump(node_json, outfile)\n",
    "    with open(edge_path, 'w') as outfile:\n",
    "        json.dump(edge_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Use these two functions for processed node data\n",
    "# def count_nodes_edges(hashtag_list, keep=20):\n",
    "#     # Count all the nodes\n",
    "#     node_counts_full = Counter()\n",
    "#     for hashtags in hashtag_list:\n",
    "#         for h in hashtags:\n",
    "#             node_counts_full[h] += 1\n",
    "\n",
    "#     # Only keep the top `keep` tags\n",
    "#     top_tags_dict = sorted(node_counts_full.items(), key=lambda x:x[1], reverse=True)[:keep]\n",
    "#     node_counts = {k:v for k,v in top_tags_dict}\n",
    "#     top_tags = list(node_counts.keys())\n",
    "    \n",
    "#     # Count the edges for top tags\n",
    "#     edge_counts = Counter()\n",
    "#     seen_tags = []\n",
    "#     for hashtags in hashtag_list:\n",
    "#         # Filter hashtags list\n",
    "#         hashtags_filtered = [h for h in hashtags if h in top_tags]\n",
    "#         # Count the edges\n",
    "#         tag_pairs = list(combinations(set(hashtags_filtered), r=2))\n",
    "#         for a,b in tag_pairs:\n",
    "#             edge_counts[(a,b)] += 1\n",
    "#             seen_tags.extend([a,b])\n",
    "    \n",
    "#     # Update node_counts to exclude those with no edges\n",
    "#     for node in node_counts.keys():\n",
    "#         if node not in seen_tags:\n",
    "#             del node_counts[node]\n",
    "#     return node_counts, edge_counts\n",
    "\n",
    "# def create_json(node_counts, edge_counts):\n",
    "#     # Convert node to json format\n",
    "#     node_json = {'nodes':[]}\n",
    "#     for i, (n,count) in enumerate(node_counts.items()):\n",
    "#         node_json['nodes'].append({'tag_name':n,\n",
    "#                                    'tag_count':count,\n",
    "#                                    'id':i})\n",
    "\n",
    "#     # Create dict that maps tag to id\n",
    "#     node_2_id = {tag_d['tag_name']:tag_d['id'] for tag_d in node_json['nodes']}\n",
    "\n",
    "#     # Convert edges to json format\n",
    "#     edge_json = {'edges':[]}\n",
    "#     for (a,b), count in edge_counts.items():\n",
    "#         source, target = node_2_id[a], node_2_id[b]\n",
    "#         edge_json['edges'].append({'source_tag':a,\n",
    "#                                    'target_tag':b,\n",
    "#                                    'source':source,\n",
    "#                                    'target':target,\n",
    "#                                    'edge_count':count})\n",
    "#     return node_json, edge_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use this block functions for processed node data\n",
    "\n",
    "# # Read in data\n",
    "# df = pd.read_csv(config.data / 'covid19_tweets_final.csv')\n",
    "\n",
    "# # Create save path\n",
    "# tag_net_path = config.data / 'tag_network'\n",
    "# if not tag_net_path.exists(): \n",
    "#     tag_net_path.mkdir()\n",
    "# node_path = tag_net_path / 'node.json'\n",
    "# edge_path = tag_net_path / 'edge.json'\n",
    "\n",
    "# # Create nodes and edges json\n",
    "# hashtag_list = extractHashTags(df['full_text'], preprocess=True)\n",
    "# node_counts, edge_counts = count_nodes_edges(hashtag_list, keep=20)\n",
    "# node_json, edge_json = create_json(node_counts, edge_counts)\n",
    "# save_json(node_json, edge_json, node_path, edge_path)\n",
    "\n",
    "# with open(node_path, 'r') as outfile:\n",
    "#     node_json = json.load(outfile)\n",
    "    \n",
    "# with open(edge_path, 'r') as outfile:\n",
    "#     edge_json = json.load(outfile)\n",
    "    \n",
    "# print(node_json['nodes'][:5])\n",
    "# print(edge_json['edges'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this function for getting data ready for d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function for getting data ready for d3\n",
    "def create_json(df, hashtag_list):\n",
    "    # Parse Nodes json\n",
    "    node_json = {'nodes':[]}\n",
    "\n",
    "    for hashtags, row_id, date, senti in zip(hashtag_list, df['id'], df['date_short'], df['senti']):\n",
    "        for tag in hashtags:\n",
    "            node_info = {'row_id': row_id,\n",
    "                         'date': date,\n",
    "                         'tag': tag,\n",
    "                         'senti': senti}\n",
    "            node_json['nodes'].append(node_info)\n",
    "\n",
    "    print(\"Total number of hashtags parsed:\", len(node_json['nodes']))\n",
    "\n",
    "    # Parse Edges json\n",
    "    edge_json = {'edges':[]}\n",
    "    for hashtags, row_id, date in zip(hashtag_list, df['id'], df['date_short']):\n",
    "        # Generate tag pairs\n",
    "        tag_pairs = list(combinations(hashtags, r=2))\n",
    "        for a,b in tag_pairs:\n",
    "            edge_info = {'row_id': row_id,\n",
    "                         'date': date,\n",
    "                         'source_tag':a,\n",
    "                         'target_tag':b}\n",
    "            edge_json['edges'].append(edge_info)\n",
    "    print(\"Total number of edges parsed:\", len(edge_json['edges']))\n",
    "    \n",
    "    # Add node id to both dicts\n",
    "    unique_tags = list(set(tag['tag'] for tag in node_json['nodes']))\n",
    "    node_2_id = {t:i for i,t in enumerate(unique_tags)}\n",
    "\n",
    "    for node_info in node_json['nodes']:\n",
    "        node_info.update({\"tag_id\":node_2_id[node_info['tag']]})\n",
    "        \n",
    "    for edge_info in edge_json['edges']:\n",
    "        source = node_2_id[edge_info['source_tag']]\n",
    "        target = node_2_id[edge_info['target_tag']]\n",
    "        edge_info.update({'source': source, 'target': target})\n",
    "             \n",
    "    return node_json, edge_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of hashtags parsed: 58431\n",
      "Total number of edges parsed: 101835\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv(config.data / 'covid19_tweets_final.csv')\n",
    "df['senti'] = (np.where(df['sentiment_tag_hf']==\"NEGATIVE\", -1, 1)) * df['sentiment_score_hf']\n",
    "\n",
    "# Create save path\n",
    "tag_net_path = config.data / 'tag_network'\n",
    "if not tag_net_path.exists(): \n",
    "    tag_net_path.mkdir()\n",
    "node_path = tag_net_path / 'node.json'\n",
    "edge_path = tag_net_path / 'edge.json'\n",
    "\n",
    "# Create nodes and edges json\n",
    "hashtag_list = extractHashTags(df['full_text'], preprocess=True)\n",
    "node_json, edge_json = create_json(df, hashtag_list)\n",
    "save_json(node_json, edge_json, node_path, edge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'row_id': 2, 'date': '2020-01-27', 'tag': '#Wuhan', 'senti': -0.9802840948104858, 'tag_id': 17000}, {'row_id': 2, 'date': '2020-01-27', 'tag': '#nCoV2019', 'senti': -0.9802840948104858, 'tag_id': 7113}, {'row_id': 6, 'date': '2020-01-27', 'tag': '#wuhan', 'senti': -0.9962654113769532, 'tag_id': 21618}, {'row_id': 6, 'date': '2020-01-27', 'tag': '#Coronavirus', 'senti': -0.9962654113769532, 'tag_id': 9541}, {'row_id': 8, 'date': '2020-01-27', 'tag': '#Coronavirus', 'senti': -0.9977931380271912, 'tag_id': 9541}]\n",
      "[{'row_id': 2, 'date': '2020-01-27', 'source_tag': '#Wuhan', 'target_tag': '#nCoV2019', 'source': 17000, 'target': 7113}, {'row_id': 6, 'date': '2020-01-27', 'source_tag': '#wuhan', 'target_tag': '#Coronavirus', 'source': 21618, 'target': 9541}, {'row_id': 10, 'date': '2020-01-27', 'source_tag': '#Coronavirus', 'target_tag': '#WuhanOutbreak', 'source': 9541, 'target': 11291}, {'row_id': 10, 'date': '2020-01-27', 'source_tag': '#Coronavirus', 'target_tag': '#Wuhanvirus', 'source': 9541, 'target': 14760}, {'row_id': 10, 'date': '2020-01-27', 'source_tag': '#WuhanOutbreak', 'target_tag': '#Wuhanvirus', 'source': 11291, 'target': 14760}]\n"
     ]
    }
   ],
   "source": [
    "with open(node_path, 'r') as outfile:\n",
    "    node_json = json.load(outfile)\n",
    "    \n",
    "with open(edge_path, 'r') as outfile:\n",
    "    edge_json = json.load(outfile)\n",
    "    \n",
    "print(node_json['nodes'][:5])\n",
    "print(edge_json['edges'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
