{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tweet import config\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import scipy.sparse as ssp\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308065, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>full_text</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>sentiment_tag_hf</th>\n",
       "      <th>sentiment_score_hf</th>\n",
       "      <th>sentiment_score_tb</th>\n",
       "      <th>subjectivity_score_tb</th>\n",
       "      <th>sentiment_score_nltk</th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>senti</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taya ❤</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I don't follow back</td>\n",
       "      <td>2011-10-01 05:55:50</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>8324</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-01-27 00:24:01</td>\n",
       "      <td>Wildfires\\nWar\\nTaal Erruption\\nJadine's break...</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>0</td>\n",
       "      <td>year grabe january</td>\n",
       "      <td>-0.997167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taya ❤</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I don't follow back</td>\n",
       "      <td>2011-10-01 05:55:50</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>8324</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-01-27 00:24:01</td>\n",
       "      <td>Wildfires\\nWar\\nTaal Erruption\\nJadine's break...</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus kobe</td>\n",
       "      <td>-0.997167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eric Ng</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Hong Kong-based senior business reporter, Sout...</td>\n",
       "      <td>2015-02-23 12:28:27</td>\n",
       "      <td>1000</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-27 00:37:26</td>\n",
       "      <td>Wuhan virus shot in the arm for health care st...</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>1</td>\n",
       "      <td>casinos hurt s</td>\n",
       "      <td>-0.999039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Ng</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Hong Kong-based senior business reporter, Sout...</td>\n",
       "      <td>2015-02-23 12:28:27</td>\n",
       "      <td>1000</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-27 00:37:26</td>\n",
       "      <td>Wuhan virus shot in the arm for health care st...</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>1</td>\n",
       "      <td>wuhan virus shot</td>\n",
       "      <td>-0.999039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Ng</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Hong Kong-based senior business reporter, Sout...</td>\n",
       "      <td>2015-02-23 12:28:27</td>\n",
       "      <td>1000</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-27 00:37:26</td>\n",
       "      <td>Wuhan virus shot in the arm for health care st...</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>1</td>\n",
       "      <td>health care stocks</td>\n",
       "      <td>-0.999039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_name user_location                                   user_description  \\\n",
       "0    Taya ❤           NaN                                I don't follow back   \n",
       "1    Taya ❤           NaN                                I don't follow back   \n",
       "2   Eric Ng     Hong Kong  Hong Kong-based senior business reporter, Sout...   \n",
       "3   Eric Ng     Hong Kong  Hong Kong-based senior business reporter, Sout...   \n",
       "4   Eric Ng     Hong Kong  Hong Kong-based senior business reporter, Sout...   \n",
       "\n",
       "          user_created  user_followers  user_friends  user_favourites  \\\n",
       "0  2011-10-01 05:55:50             283             0             8324   \n",
       "1  2011-10-01 05:55:50             283             0             8324   \n",
       "2  2015-02-23 12:28:27            1000           191                1   \n",
       "3  2015-02-23 12:28:27            1000           191                1   \n",
       "4  2015-02-23 12:28:27            1000           191                1   \n",
       "\n",
       "   user_verified                date  \\\n",
       "0          False 2020-01-27 00:24:01   \n",
       "1          False 2020-01-27 00:24:01   \n",
       "2           True 2020-01-27 00:37:26   \n",
       "3           True 2020-01-27 00:37:26   \n",
       "4           True 2020-01-27 00:37:26   \n",
       "\n",
       "                                           full_text  ... tweet_length  \\\n",
       "0  Wildfires\\nWar\\nTaal Erruption\\nJadine's break...  ...          112   \n",
       "1  Wildfires\\nWar\\nTaal Erruption\\nJadine's break...  ...          112   \n",
       "2  Wuhan virus shot in the arm for health care st...  ...          102   \n",
       "3  Wuhan virus shot in the arm for health care st...  ...          102   \n",
       "4  Wuhan virus shot in the arm for health care st...  ...          102   \n",
       "\n",
       "  sentiment_tag_hf sentiment_score_hf sentiment_score_tb  \\\n",
       "0         NEGATIVE           0.997167                0.0   \n",
       "1         NEGATIVE           0.997167                0.0   \n",
       "2         NEGATIVE           0.999039                0.0   \n",
       "3         NEGATIVE           0.999039                0.0   \n",
       "4         NEGATIVE           0.999039                0.0   \n",
       "\n",
       "  subjectivity_score_tb  sentiment_score_nltk  id               topic  \\\n",
       "0                   0.0               -0.7430   0  year grabe january   \n",
       "1                   0.0               -0.7430   0    coronavirus kobe   \n",
       "2                   0.0               -0.0516   1      casinos hurt s   \n",
       "3                   0.0               -0.0516   1    wuhan virus shot   \n",
       "4                   0.0               -0.0516   1  health care stocks   \n",
       "\n",
       "      senti  month  \n",
       "0 -0.997167      1  \n",
       "1 -0.997167      1  \n",
       "2 -0.999039      1  \n",
       "3 -0.999039      1  \n",
       "4 -0.999039      1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv(config.data / 'covid19_tweets_final_denormalized_topic.csv', index_col=0, encoding='utf-8')\n",
    "df = df.dropna(subset=['topic'])\n",
    "df['senti'] = (np.where(df['sentiment_tag_hf']==\"NEGATIVE\", -1, 1)) * df['sentiment_score_hf']\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.month\n",
    "df.index = range(len(df))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 1 ,Selected rows: 40\n",
      "Month: 2 ,Selected rows: 135\n",
      "Month: 3 ,Selected rows: 242\n",
      "Month: 4 ,Selected rows: 227\n",
      "Month: 5 ,Selected rows: 268\n",
      "Month: 6 ,Selected rows: 698\n",
      "Month: 7 ,Selected rows: 961\n",
      "Month: 8 ,Selected rows: 944\n",
      "Month: 9 ,Selected rows: 907\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    tokens = re.findall('(?u)\\\\b\\\\w\\\\w+\\\\b', text)\n",
    "    tokens = list(map(lemmatizer.lemmatize, tokens))\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Define constants for vectorizer\n",
    "min_df = 3\n",
    "max_df = 0.95\n",
    "max_features=20\n",
    "ngram_range=(1, 2)\n",
    "\n",
    "# Narrow down the range of topics\n",
    "issue_list = ['evict', 'mental', 'depress', 'food', 'money', 'unemploy',\n",
    "              'shut', 'bankrup', 'friend', 'credit', 'house', 'medici']\n",
    "\n",
    "# Gather info for each month\n",
    "month_dict = {int(m):0 for m in df['month'].unique()}\n",
    "\n",
    "# Get data for each month\n",
    "for m in df['month'].unique():\n",
    "    # Select relevant data\n",
    "    df_m = df[df['month'] == m]\n",
    "    selected_ids = []\n",
    "    for issue in issue_list:\n",
    "        tmp = list(df_m[df_m['topic'].str.contains(issue)].index)\n",
    "        selected_ids.extend(tmp)\n",
    "\n",
    "    selected_ids = list(set(selected_ids))\n",
    "    print(\"Month:\", m, \",Selected rows:\", len(selected_ids))\n",
    "    \n",
    "    # Filter to selected rows\n",
    "    df_m = df_m[df_m.index.isin(selected_ids)]\n",
    "    \n",
    "    # Lemmatize the texts\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    df_m['clean_topic'] = df_m['topic'].apply(clean_text)\n",
    "    \n",
    "    # Apply Tfidf\n",
    "    vec = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        token_pattern = '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features,\n",
    "        lowercase=False\n",
    "    )\n",
    "\n",
    "    # Calcualte importance based on TfidfVectorizer\n",
    "    ct_matrix = vec.fit_transform(df_m['clean_topic'].tolist());\n",
    "    vocab = list(pd.Series(vec.vocabulary_).sort_values().index)\n",
    "    word_importance = ct_matrix.sum(axis=0).A.reshape(-1).tolist()\n",
    "    import_df = pd.DataFrame({'vocab':vocab, 'importance':word_importance}).sort_values('importance', ascending=False)\n",
    "\n",
    "    # Gather data for month\n",
    "    month_data = []\n",
    "    for i, row in import_df.iterrows():\n",
    "        vocab = row.vocab\n",
    "        imp = row.importance\n",
    "        senti = df_m[df_m['clean_topic'].str.contains(vocab)]['senti'].mean()\n",
    "        month_data.append({'vocab': vocab, 'imp': imp, 'senti': senti})\n",
    "    month_dict[m] = month_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'vocab': 'money', 'imp': 127.0, 'senti': -0.7555400570854545},\n",
       " {'vocab': 'house', 'imp': 102.01948447245253, 'senti': -0.6203261329684147},\n",
       " {'vocab': 'friend', 'imp': 90.49036720597144, 'senti': -0.2993692050759609},\n",
       " {'vocab': 'food', 'imp': 74.0, 'senti': -0.4964671648001369},\n",
       " {'vocab': 'unemployment', 'imp': 62.0, 'senti': -0.90151037050016},\n",
       " {'vocab': 'mental', 'imp': 48.13751414347409, 'senti': -0.5001860078964525},\n",
       " {'vocab': 'shut', 'imp': 39.0, 'senti': -0.8379448218779131},\n",
       " {'vocab': 'mental health',\n",
       "  'imp': 32.53252404327012,\n",
       "  'senti': -0.35743666453795},\n",
       " {'vocab': 'health', 'imp': 32.53252404327012, 'senti': -0.3439453333616257},\n",
       " {'vocab': 'white', 'imp': 31.711270562160458, 'senti': -0.6124069809913635},\n",
       " {'vocab': 'white house',\n",
       "  'imp': 31.21469368959654,\n",
       "  'senti': -0.6535428214073181},\n",
       " {'vocab': 'eviction', 'imp': 29.0, 'senti': -0.7181152025858561},\n",
       " {'vocab': 'shutdown',\n",
       "  'imp': 26.757513715256046,\n",
       "  'senti': -0.7700807187292311},\n",
       " {'vocab': 'credit', 'imp': 21.0, 'senti': -0.7630935509999593},\n",
       " {'vocab': 'medicine', 'imp': 20.0, 'senti': -0.18563054696373318},\n",
       " {'vocab': 'household', 'imp': 20.0, 'senti': -0.7895559906959534},\n",
       " {'vocab': 'unemployed', 'imp': 19.0, 'senti': -0.6822962729554427},\n",
       " {'vocab': 'mentality',\n",
       "  'imp': 11.459957743725575,\n",
       "  'senti': -0.7875820084622032},\n",
       " {'vocab': 'herd mentality',\n",
       "  'imp': 8.758684689334855,\n",
       "  'senti': -0.7377895752588908},\n",
       " {'vocab': 'herd', 'imp': 8.758684689334855, 'senti': -0.7541567534208298}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_dict[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save json to disk\n",
    "save_path = config.data / 'word_cloud_data'\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir()\n",
    "with open(save_path / 'month_dict.json', 'w') as outfile:\n",
    "    json.dump(month_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
